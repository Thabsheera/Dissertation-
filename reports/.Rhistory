plot(bss_summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "b")
adj_r2_max = which.max(bss_summary$adjr2)
points(adj_r2_max, bss_summary$adjr2[adj_r2_max], col ="red", cex = 2, pch = 20)
#cp
plot(bss_summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "b")
cp_min = which.min(bss_summary$cp)
points(cp_min, bss_summary$cp[cp_min], col = "red", cex = 2, pch = 20)
#bic
plot(bss_summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "b")
bic_min = which.min(bss_summary$bic)
points(bic_min, bss_summary$bic[bic_min], col = "red", cex = 2, pch = 20)
coef(bss,6)
## Obtain regression coefficients for this model
logreg_step_fit = glm(class ~ Cl.thickness+Cell.size+Cell.shape+Bare.nuclei+Bl.cromatin+Normal.nucleoli, data=BreastCancer_new, family="binomial")
summary(logreg_step_fit)
# Compute predicted probabilities:
phat = predict(logreg_step_fit, BreastCancer_new[,c(-1,-11)], type="response")
## Compute fitted values:
yhat = ifelse(phat > 0.5, 1, 0)
## Calculate confusion matrix:
(confusion = table(Observed=BreastCancer_new[,11], Predicted=yhat))
1 - mean(BreastCancer_new[,11]==yhat)
# pick out and scale the predictor variables
X1<- BreastCancer_new[,2:10]
X1<- scale(X1)
# pick the predictor variable
Y<- BreastCancer_new[,11]
# combining both
breastcancer_lr_data<- data.frame(X1,Y)
# Store n and p
n = nrow(breastcancer_lr_data)
p = ncol(breastcancer_lr_data) - 1
# Load the bestglm package
library(bestglm)
## Apply best subset selection
#aic
bss_fit_AIC = bestglm(breastcancer_lr_data, family=binomial, IC="AIC")
#BIC
bss_fit_BIC = bestglm(breastcancer_lr_data, family=binomial, IC="BIC")
# subsets
(AIC_subsets=bss_fit_AIC$Subsets)
(BIC_subsets=bss_fit_BIC$Subsets)
(best_AIC=bss_fit_AIC$ModelReport$Bestk)
(best_BIC=bss_fit_BIC$ModelReport$Bestk)
## Create multi-panel plotting device
par(mfrow=c(1,2))
## Produce plots, highlighting optimal value of k
plot(0:p, bss_fit_AIC$Subsets$AIC, xlab="Number of predictors", ylab="AIC", type="b")
points(best_AIC, bss_fit_AIC$Subsets$AIC[best_AIC+1], col="red", pch=16)
plot(0:p, bss_fit_BIC$Subsets$BIC, xlab="Number of predictors", ylab="BIC", type="b")
points(best_BIC, bss_fit_BIC$Subsets$BIC[best_BIC+1], col="red", pch=16)
pstar = 5
## Check which predictors are in the 1-predictor model
bss_fit_BIC$Subsets[pstar+1,]
## Construct a reduced data set containing only the selected predictor
(indices = as.logical(bss_fit_BIC$Subsets[pstar+1, 2:(p+1)]))
breastcancer_lr_data_v1 = data.frame(X1[,indices], Y)
## Obtain regression coefficients for this model
logreg1_fit = glm(Y ~ ., data=breastcancer_lr_data_v1, family="binomial")
summary(logreg1_fit)
# Compute predicted probabilities:
phat = predict(logreg1_fit, breastcancer_lr_data_v1[,c(-6)], type="response")
## Compute fitted values:
yhat = ifelse(phat > 0.5, 1, 0)
1 - mean(breastcancer_lr_data_v1[,6]==yhat)
# Load the glmnet package
library(glmnet)
## Choose grid of values for the tuning parameter
grid = 10^seq(-5, 1, length.out=100)
## Fit a model with LASSO penalty for each value of the tuning parameter
lasso_fit = glmnet(X1, Y, family="binomial", alpha=1, standardize=FALSE, lambda=grid)
summary(lasso_fit)
# Examine the effect of the tuning parameter on the parameter estimates
plot(lasso_fit, xvar="lambda", col=1:10, label=TRUE)
lasso_cv_fit = cv.glmnet(X1, Y, family="binomial", alpha=1, standardize=FALSE, lambda=grid,
type.measure="class")
plot(lasso_cv_fit)
# Identify the optimal value for the tuning parameter
(lambda_lasso_min = lasso_cv_fit$lambda.min)
which_lambda_lasso = which(lasso_cv_fit$lambda == lambda_lasso_min)
## Find the parameter estimates associated with optimal value of the tuning parameter
coef(lasso_fit, s=lambda_lasso_min)
# Compute predicted probabilities:
phat = predict(lasso_fit, X1, s=lambda_lasso_min, type="response")
## Compute fitted values:
yhat = ifelse(phat > 0.5, 1, 0)
## Calculate confusion matrix:
(confusion = table(Observed=Y, Predicted=yhat))
1 - mean(Y==yhat)
# Load the glmnet package
library(glmnet)
## Choose grid of values for the tuning parameter
grid = 10^seq(-4, 2, length.out=100)
## Fit a model with ridge penalty for each value of the tuning parameter
ridge_fit = glmnet(X1, Y, family="binomial", alpha=0, standardize=FALSE, lambda=grid)
# Examine the effect of the tuning parameter on the parameter estimates
plot(ridge_fit, xvar="lambda", col=1:10, label=TRUE)
# running cros validation to get lambda
ridge_cv_fit = cv.glmnet(X1, Y, family="binomial", alpha=0, standardize=FALSE, lambda=grid,
type.measure="class")
plot(ridge_cv_fit)
# Identify the optimal value for the tuning parameter
(lambda_ridge_min = ridge_cv_fit$lambda.min)
which_ridge_lasso = which(ridge_cv_fit$lambda == lambda_ridge_min)
## Find the parameter estimates associated with optimal value of the tuning parameter
coef(ridge_fit, s=lambda_ridge_min)
# Compute predicted probabilities:
phat = predict(ridge_fit, X1, s=lambda_ridge_min, type="response")
## Compute fitted values:
yhat = ifelse(phat > 0.5, 1, 0)
## Calculate confusion matrix:
(confusion = table(Observed=Y, Predicted=yhat))
1 - mean(Y==yhat)
# Load the MASS package
library(MASS)
# Sample indices of training data:
train_set = sample(c(TRUE, FALSE), nrow(breastcancer_lr_data), replace=TRUE)
# Perform LDA:
(lda_train=lda(Y~., data=breastcancer_lr_data[train_set,]))
library(klaR)
library(MASS)
#par(mar=c(1,1,1,1))
partimat(Y ~ ., data = breastcancer_lr_data, method = "lda")
# Compute fitted values for the validation data:
lda_test = predict(lda_train, breastcancer_lr_data[!train_set,])
yhat_test = lda_test$class
1 - mean(breastcancer_lr_data$Y[!train_set] == yhat_test)
# Load the nclSLR package
library(nclSLR)
library(MASS)
## Perform QDA on the training data:
(qda_train = qda(Y~., data=breastcancer_lr_data[train_set,]))
# Compute fitted values for the validation data:
qda_test = predict(qda_train, breastcancer_lr_data[!train_set,])
yhat_test = qda_test$class
## Compute test error:
1 - mean(breastcancer_lr_data$Y[!train_set] == yhat_test)
# Set the seed to make the analysis reproducible
set.seed(1)
# 10-fold cross validation
nfolds = 10
## Sample fold-assignment index
fold_index = sample(nfolds, n, replace=TRUE)
## Print first few fold-assignments
head(fold_index)
#Function to estimate the test error:
# inputting the predictor and dependent variables, folds index,  and methos which asks if it's lasso, lda or bic
reg_cv = function(X1, Y, fold_ind,method) {
Xy = data.frame(X1, Y=Y) # combining the predictor and output
nfolds = max(fold_ind)
if(!all.equal(sort(unique(fold_ind)), 1:nfolds)) stop("Invalid fold partition.")
cv_errors = numeric(nfolds) # creating a numeric vector to store error
for(fold in 1:nfolds) { # loooping over each fold
if (method=="BIC") { #running model and predicting for BIC
#using only the 5 variables selected from best subset selection models
tmp_fit = glm(Y ~ Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli, data=Xy[fold_ind!=fold,], family="binomial")
phat = predict(tmp_fit, Xy[fold_ind==fold,],
type="response")
## Compute fitted values:
yhat = ifelse(phat > 0.5, 1, 0)
}else if (method=="lasso") { # model for lasso
#using the lambda values obtained in the model
tmp_fit = glmnet(Xy[fold_ind!=fold,-10], Xy[fold_ind!=fold,]$Y, family="binomial", alpha=1, standardize=FALSE, lambda=lambda_lasso_min)
phat = predict(tmp_fit, X1[fold_ind==fold,],
type="response")
## Compute fitted  values:
yhat = ifelse(phat > 0.5, 1, 0)
} else { # model for LDA
tmp_fit=lda(Y~., data=Xy[fold_ind!=fold,]) # training
lda_test = predict(tmp_fit, Xy[fold_ind==fold,]) # predicting
yhat=lda_test$class
}
# finding the confusion matrix
(confusion = table(Observed=Xy[fold_ind==fold,]$Y, Predicted=yhat))
# storing the error
cv_errors[fold] = 1 - mean(Xy[fold_ind==fold,]$Y==yhat)
}
# taking the average of error across the folds
fold_sizes = numeric(nfolds)
for(fold in 1:nfolds) fold_sizes[fold] = length(which(fold_ind==fold))
test_error = weighted.mean(cv_errors, w=fold_sizes)
return(test_error)
}
# calling the function for BIC
reg_cv(X1,Y,fold_index,method = "BIC")
# calling the function for lasso
reg_cv(X1,Y,fold_index,method = "lasso")
# calling the function for lda
reg_cv(X1,Y,fold_index,method = "LDA")
??read.sps
library(foreign)
ff<- read.spss("D:/MSc DS/Dessertatin/Behaviour Data/8128spss_BCBFC942835A6A827A7A0368519B6CAAD2049EFD940BF31A1A226FE01630B89E_V1/UKDA-8128-spss/spss/spss19/uktus15_diary_ep_long.sav")
View(ff)
dd<- data.frame(ff)
View(dd)
knitr::opts_chunk$set(echo = TRUE)
reticulate::repl_python()
print("hello)
reticulate::repl_python()
print("hello")
reticulate::repl_python()
print('hello')
install.packages("reticulate",dependencies = T)
reticulate::repl_python()
print('hello')
yes
reticulate::repl_python()
print('hello')
quit
reticulate::repl_python()
print('hello')
quit
reticulate::repl_python()
print('hello')
import pandas
quit
reticulate::repl_python()
print('hello')
import sys
quit
reticulate::repl_python()
print('hello')
import sys
!{sys.executable} -m pip install pandas
quit
reticulate::repl_python()
import pandas
quit
reticulate::repl_python()
pip install pandas
import pandas
quit
reticulate::repl_python()
!pip install pandas
import pandas
quit
reticulate::repl_python()
# !pip install pandas
import pandas
getwd()
exit
getwd()
setwd("D:/MSc DS/CSC8639  Project and Dissertation in Data Science//")
setwd("NICA_Behavioral_Analytics/reports/")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)
load.project()
View(uktus15_individual)
length(unique(paste(uktus15_individual$serial,uktus15_individual$pnum))
)
length(unique(paste(uktus15_diary_ep_long$serial,uktus15_diary_ep_long$pnum)))
include_graphics("RDMP_Thabsheera.pdf")
knitr::include_graphics("RDMP_Thabsheera.pdf")
knitr::include_graphics("RDMP_Thabsheera.pdf")
knitr::include_graphics(path = "Project_Plan.jpg")
knitr::include_graphics(path = "Project_Plan.jpg")
knitr::include_graphics(path = "Project_Plan.jpg")
knitr::include_graphics(path = "Project_Plan.JPG")
knitr::include_graphics(path = "Project_Plan.JPG")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)
load.project()
activity_freq<- uktus15_diary_ep_long%>%
group_by(whatdoing)%>%
summarise(freq= n(),
ratio=round((freq/587632)*100,2))%>%
arrange(desc(freq))
# activity except sleep/eating
activity_freq_wo_slp_eat<- uktus15_diary_ep_long%>%
filter(!whatdoing %in% c('Eating','Sleep'))%>%
group_by(whatdoing)%>%
summarise(freq= n(),
ratio=round((freq/470855)*100,2))%>%
arrange(desc(freq))
ggplot(activity_freq,aes(x="",y=freq,fill=whatdoing))+
geom_bar(stat="identity", width=1) +
coord_polar("y", start=0)+theme_void()+
#theme(legend.position="none") +
theme(legend.text=element_text(size=4))
# geom_text(aes(y=freq,label=whatdoing),size=2,
#           position = position_stack(vjust = 0.5))
hist(uktus15_diary_ep_long$whatdoing)
ggplot(activity_freq,aes(x=tid,y=whatdoing,size=freq))+
geom_point()
View(uktus15_diary_ep_long%>%
filter(tid %like% "^10")
)
library(dplye)
library(dplyr)
View(uktus15_diary_ep_long%>%
filter(tid %like% "^10")
)
# ggplot(activity_freq,aes(x=tid,y=whatdoing,size=freq))+
#   geom_point()
library(data.table)
View(uktus15_diary_ep_long%>%
filter(tid %like% "^10")
)
summary(uktus15_diary_ep_long)
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
group_by(Macro.Group,dow)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_grid(. ~ dow)
unique(diary_ind_mapped$dhhtype)
sum(is.na(diary_ind_mapped$dhhtype))
macro_behavior_freq_hhtype<- diary_ind_mapped%>%
filter(!is.na(dhhtype))%>%
mutate(hhtype=ifelse(grepl(x = dhhtype,pattern = 'with children',ignore.case = TRUE),"Household With Children",
ifelse(dhhtype=='Single person household','Single person household',
'Household Without Children'))
)%>%
group_by(Macro.Group,hhtype)%>%
summarise(Freq=n(),
hh_count=n_distinct(serial),
Freq_per_hh=Freq/hh_count)%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq_hhtype,aes(x=reorder(Macro.Group,-Freq_per_hh),y=Freq_per_hh))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_grid(. ~ hhtype)
diary_ind_mapped$DVAge<- as.numeric(as.character(diary_ind_mapped$DVAge))
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
mutate(age_group=ifelse(DVAge<=14,'Children',
ifelse(DVAge<=24 ,'Youth',
ifelse(DVAge<=64,'Adults',
'Seniors'))))%>%
group_by(Macro.Group,age_group)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ age_group)
View(data.frame(colnames(diary_ind_mapped)))
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
mutate(age_group=ifelse(DVAge<=14,'Children',
ifelse(DVAge<=24 ,'Youth',
ifelse(DVAge<=64,'Adults',
'Seniors'))))%>%
group_by(Macro.Group,generation)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ generation)
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
group_by(Macro.Group,WhereWhen)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq%>%
filter(Macro.Group=='social life and entertainment'),
aes(x=reorder(WhereWhen,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Macro.Group)
macro_behavior_freq<- diary_ind_mapped%>%
filter(!Enjoy %in% c('NA','not reported'))%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
mutate(age_group=ifelse(DVAge<=14,'Children',
ifelse(DVAge<=24 ,'Youth',
ifelse(DVAge<=64,'Adults',
'Seniors'))))%>%
group_by(Macro.Group,Enjoy)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Enjoy)
plot_fn <- function(x) {
p<-ggplot(macro_behavior_freq%>%
filter(Enjoy==x),
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Enjoy)
return(p)
}
enjoy_1<-plot_fn('not at all')
enjoy_2<-plot_fn('2')
enjoy_3<-plot_fn('3')
enjoy_4<-plot_fn('4')
enjoy_5<-plot_fn('5')
enjoy_6<-plot_fn('6')
enjoy_7<-plot_fn('very much')
enjoy_1
enjoy_7
enjoy_4
test<- diary_ind_mapped%>% mutate(pnum_hous=paste(serial,pnum))%>%group_by(generation)%>%summarise(peeps=n_distinct(pnum_hous))
View(test)
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
mutate(age_group=ifelse(DVAge<=14,'Children',
ifelse(DVAge<=24 ,'Youth',
ifelse(DVAge<=64,'Adults',
'Seniors'))))%>%
group_by(Macro.Group,generation)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ generation)
View(test)
sum(test$peeps)
2285+1987
4272/8274
macro_behavior_freq<- diary_ind_mapped%>%
group_by(Macro.Group,Psychosocial_Stages)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Psychosocial_Stages)
unique(macro_behavior_freq$Psychosocial_Stages)
ggplot(macro_behavior_freq%>%
filter(Psychosocial_Stages%in% c("50-57","58-67","68-74","75-84","85-94","95+")),
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Psychosocial_Stages)
ggplot(macro_behavior_freq%>%
filter(Psychosocial_Stages%in% c("50-57","58-67","68-74","75-84")),
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Psychosocial_Stages)
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
mutate(age_group=ifelse(DVAge<=14,'Children',
ifelse(DVAge<=24 ,'Youth',
ifelse(DVAge<=64,'Adults',
'Seniors'))))%>%
group_by(Macro.Group,generation)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ generation)
unique(macro_behavior_freq$generation)
ggplot(macro_behavior_freq%>%
filter(generation %in% c("Baby Boomers" ,"Gen X")),
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ generation)
macro_behavior_freq<- diary_ind_mapped%>%
group_by(Macro.Group,Psychosocial_Stages)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq%>%
filter(Psychosocial_Stages%in% c("50-57","58-67","68-74","75-84")),
aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_wrap(. ~ Psychosocial_Stages)
macro_behavior_freq<- diary_ind_mapped%>%
mutate(dow=ifelse(ddayw %in% c('Saturday','Sunday') , 'Sat-Sun','Mon-Fri'))%>%
group_by(Macro.Group,dow)%>%
summarise(Freq=n())%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq,aes(x=reorder(Macro.Group,-Freq),y=Freq))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_grid(. ~ dow)
macro_behavior_freq_hhtype<- diary_ind_mapped%>%
filter(!is.na(dhhtype))%>%
mutate(hhtype=ifelse(grepl(x = dhhtype,pattern = 'with children',ignore.case = TRUE),"Household With Children",
ifelse(dhhtype=='Single person household','Single person household',
'Household Without Children'))
)%>%
group_by(Macro.Group,hhtype)%>%
summarise(Freq=n(),
hh_count=n_distinct(serial),
Freq_per_hh=Freq/hh_count)%>%
arrange(desc(Freq))
ggplot(macro_behavior_freq_hhtype,aes(x=reorder(Macro.Group,-Freq_per_hh),y=Freq_per_hh))+
geom_col()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size = 7))+
facet_grid(. ~ hhtype)
enjoy_7
enjoy_6
enjoy_5
shiny::runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
unique(diary_ind_mapped$ddayw)
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
unique(diary_ind_mapped$dhhtype)
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
runApp('D:/MSc DS/CSC8639  Project and Dissertation in Data Science/NICA_behavioral_Analytics/reports/behaviour_analytics')
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics(path = "shiny_ss.JPG")
knitr::include_graphics(path = "shiny_ss.JPG")
